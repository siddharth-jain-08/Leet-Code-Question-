{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 677,
   "id": "b27505a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score,precision_score,recall_score\n",
    "from scipy.sparse import hstack\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "id": "beb8f27a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>similar_questions</th>\n",
       "      <th>topic_tags</th>\n",
       "      <th>hints</th>\n",
       "      <th>topic</th>\n",
       "      <th>totalAccepted</th>\n",
       "      <th>totalSubmission</th>\n",
       "      <th>acRate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540</td>\n",
       "      <td>singl element sort array</td>\n",
       "      <td>given sort array consist integ everi element a...</td>\n",
       "      <td>Medium</td>\n",
       "      <td>4873</td>\n",
       "      <td>110</td>\n",
       "      <td>[]</td>\n",
       "      <td>Array Binary Search</td>\n",
       "      <td>singl element sort array</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>281300</td>\n",
       "      <td>479400</td>\n",
       "      <td>58.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>919</td>\n",
       "      <td>project area 3d shape</td>\n",
       "      <td>given grid place cube axi align axe valu grid ...</td>\n",
       "      <td>Easy</td>\n",
       "      <td>387</td>\n",
       "      <td>1135</td>\n",
       "      <td>[]</td>\n",
       "      <td>Array Math Geometry Matrix</td>\n",
       "      <td>project area 3d shape</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>39800</td>\n",
       "      <td>56900</td>\n",
       "      <td>69.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>493</td>\n",
       "      <td>revers pair</td>\n",
       "      <td>given integ array num return number revers pai...</td>\n",
       "      <td>Hard</td>\n",
       "      <td>2641</td>\n",
       "      <td>176</td>\n",
       "      <td>['Count of Smaller Numbers After Self', 'Count...</td>\n",
       "      <td>Array Binary Search Divide and Conquer Binary ...</td>\n",
       "      <td>revers pair</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>79500</td>\n",
       "      <td>266800</td>\n",
       "      <td>29.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2045</td>\n",
       "      <td>cut ribbon</td>\n",
       "      <td>cut ribbon</td>\n",
       "      <td>Medium</td>\n",
       "      <td>340</td>\n",
       "      <td>20</td>\n",
       "      <td>['Capacity To Ship Packages Within D Days', 'A...</td>\n",
       "      <td>Array Binary Search</td>\n",
       "      <td>use binari search answer can get branch length...</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>34100</td>\n",
       "      <td>70800</td>\n",
       "      <td>48.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2141</td>\n",
       "      <td>smallest greater multipl made two digit</td>\n",
       "      <td>smallest greater multipl made two digit</td>\n",
       "      <td>Medium</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>Math Enumeration</td>\n",
       "      <td>could generat differ number compris digit1 dig...</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>864</td>\n",
       "      <td>1600</td>\n",
       "      <td>52.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_id                                    title  \\\n",
       "0          540                 singl element sort array   \n",
       "1          919                    project area 3d shape   \n",
       "2          493                              revers pair   \n",
       "3         2045                               cut ribbon   \n",
       "4         2141  smallest greater multipl made two digit   \n",
       "\n",
       "                                             content difficulty  likes  \\\n",
       "0  given sort array consist integ everi element a...     Medium   4873   \n",
       "1  given grid place cube axi align axe valu grid ...       Easy    387   \n",
       "2  given integ array num return number revers pai...       Hard   2641   \n",
       "3                                         cut ribbon     Medium    340   \n",
       "4            smallest greater multipl made two digit     Medium     18   \n",
       "\n",
       "   dislikes                                  similar_questions  \\\n",
       "0       110                                                 []   \n",
       "1      1135                                                 []   \n",
       "2       176  ['Count of Smaller Numbers After Self', 'Count...   \n",
       "3        20  ['Capacity To Ship Packages Within D Days', 'A...   \n",
       "4         3                                                 []   \n",
       "\n",
       "                                          topic_tags  \\\n",
       "0                                Array Binary Search   \n",
       "1                         Array Math Geometry Matrix   \n",
       "2  Array Binary Search Divide and Conquer Binary ...   \n",
       "3                                Array Binary Search   \n",
       "4                                   Math Enumeration   \n",
       "\n",
       "                                               hints       topic  \\\n",
       "0                           singl element sort array  Algorithms   \n",
       "1                              project area 3d shape  Algorithms   \n",
       "2                                        revers pair  Algorithms   \n",
       "3  use binari search answer can get branch length...  Algorithms   \n",
       "4  could generat differ number compris digit1 dig...  Algorithms   \n",
       "\n",
       "   totalAccepted  totalSubmission  acRate  \n",
       "0         281300           479400    58.7  \n",
       "1          39800            56900    69.9  \n",
       "2          79500           266800    29.8  \n",
       "3          34100            70800    48.1  \n",
       "4            864             1600    52.4  "
      ]
     },
     "execution_count": 678,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('cleaned_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "id": "90f43e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question_id          0\n",
       "title                0\n",
       "content              0\n",
       "difficulty           0\n",
       "likes                0\n",
       "dislikes             0\n",
       "similar_questions    0\n",
       "topic_tags           0\n",
       "hints                0\n",
       "topic                0\n",
       "totalAccepted        0\n",
       "totalSubmission      0\n",
       "acRate               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 679,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "id": "e222f4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#since the dataset is limited hence instead of using all the tags I will filter only the most important tags and train model on it\n",
    "#check the number of topic tags and the data coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "id": "16ac850d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary='true' will give a binary vectorizer\n",
    "vectorizer = CountVectorizer(tokenizer = lambda x: x.split(), binary='true')\n",
    "multilabel_y = vectorizer.fit_transform(df['topic_tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "id": "4e46436f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tags_to_choose(n):\n",
    "    t = multilabel_y.sum(axis=0).tolist()[0]\n",
    "    sorted_tags_i = sorted(range(len(t)), key=lambda i: t[i], reverse=True)\n",
    "    multilabel_yn=multilabel_y[:,sorted_tags_i[:n]]\n",
    "    return multilabel_yn\n",
    "\n",
    "def questions_explained_fn(n):\n",
    "    multilabel_yn = tags_to_choose(n)\n",
    "    x= multilabel_yn.sum(axis=1)\n",
    "    return (np.count_nonzero(x==0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "id": "1b02b792",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_explained = []\n",
    "total_tags=multilabel_y.shape[1]\n",
    "total_qs=df.shape[0]\n",
    "for i in range(0, total_tags, 12):\n",
    "    questions_explained.append(np.round(((total_qs-questions_explained_fn(i))/total_qs)*100,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "id": "4c975a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAoTElEQVR4nO3deZxcZZ3v8c+3l6ydPRADCSQBUSMqkgABHCWi110YVEbGBZURx6uI4MyVcXS8jjP36ii464iCMm4REYVhYASdgBemO5CELRCEdCeEsAW6s3X27v7dP87pTtH0Uqnu6lOn6/t+verV55yqOuebperX53nOeR5FBGZmZgA1WQcwM7PK4aJgZmY9XBTMzKyHi4KZmfVwUTAzsx51WQcYipkzZ8a8efNKeu/OnTuZOHHi8AYqozzlzVNWyFfePGWFfOXNU1YYWt5Vq1Y9GxGH9PlkROT2sWjRoijV8uXLS35vFvKUN09ZI/KVN09ZI/KVN09ZI4aWF1gZ/XyvuvnIzMx6uCiYmVkPFwUzM+vhomBmZj1cFMzMrEfZioKkKyVtlrSmYNt0SbdIeiT9OS3dLknflLRO0n2Sji9XLjMz6185zxR+DLyx17ZLgD9ExAuBP6TrAG8CXpg+zge+V8ZcZmbWj7LdvBYRf5Q0r9fmM4DT0uWrgFuBT6fb/y29frZJ0lRJsyPiyXLlM7PqEBF0BXR0ddHRGXR0BZ1dQUdXV/Iz3fZEexePPL2DroCuSF4T6XJXuo/ufXVvO/A8dHUdeF1Xes1/V8Hz0b2fLnre29l7312F7+d5++vsOrA8dXdnz5fpcFKUcT6FtCjcEBHHputbI2JquixgS0RMlXQD8KWIuD197g/ApyNiZR/7PJ/kbIJZs2YtWrZsWUnZ2tvbaWhoKOm9WchT3krO2tkV7O6A3R3Bro5keeeu3YwbNx6AA5+GZKn741H4Kele7v3R6f1J6uu93duft63XQvSzffeePYwbN+65eXoFGSxff8caMPMg+yT62D+we89e6saMoSugsws6g2Q5/bJ77rbk36dwvfu1yZdhr9emX7DP29bHfkcbAWcfFbzphaV9zpYuXboqIhb39Vxmw1xEREg66H+uiLgcuBxg8eLFcdppp5V0/FtvvZVS35uFPOUtV9aurmDH3g527NnPjj0d7NjTwfbd+9mxt2B9z3627y58zf6e7Tv2dLBrX2cfexawZ9jzloeAvVmHOAgC9ves1dWI2hod+FlbQ133eq2oq6npeb6uVtTW1DCm13r3e+t7rXe/pnAfhcco3FZfW/O89YfWruXYYxdSI1EjkEStRE1Nsty9vUZC6c/C13Y/V1sz8PM9769JttVKz3++hkGPV67P2UgXhae7m4UkzQY2p9sfB+YWvG5Ous1GiYhg577O5Eu815f19j19fInvPvBF3/Pc3o5BjzOmrobJ4+qYNK6eSePqmDyunlmTxzGp17bC9TX33csrX/lKpGQf6Y+e9e4thc8rXen9WvV6LQM83997Bjr+nSvu5KSTTkzXdfDHHyB37+MzaL7n70s890WNd9zOaa95dc+Xr3oHqyC3bnuE015+WNYxMjfSReF64FzgS+nP6wq2f1zSMuAkYJv7E/JnX0cX167exC9X7+G7f2p8TgFo39tB1yDnhfW16vminjSujklj65k3c0LBtnom9/GlXrg8rr72oHPv31TLifOnl/inHlmPNdSw4JDKbJrry7g6lfRvYtkpW1GQ9AuSTuWZkjYBnycpBldLOg94FDg7ffmNwJuBdcAu4IPlymXDr7sYfHv5OjZt2c2sCWLeRJgzbULyJT7++V/ek3t90U8aV8+4+pqK/k3SrBqU8+qjc/p56vQ+XhvAx8qVxcqjdzF4xdypfPHMY+GJB1i69OSs45lZCXI9n4Jlo79icNoxhyQdYE8+mHVEMyuRi4IVbbBiYGb556Jgg3IxMKseLgrWLxcDs+rjomDP42JgVr1cFKyHi4GZuSiYi4GZ9XBRqGIuBmbW26BFQdK1wBXATRHRVf5IVm4uBmbWn2LOFL5LMuzENyX9CvhRRPypvLGsHFwMzGwwgxaFiPg98HtJU4Bz0uXHgB8AP42I/QPuwDLnYmBmxSqqT0HSDOC9wPuAu4GfAa8iGen0tHKFs6FxMTCzg1VMn8JvgBcBPwHeVjCk9S8lPW9mNMuei4GZlaqYM4VvRsTyvp7obzo3y4aLgZkNVb9FQdJZfS13i4hryxXKDo6LgZkNl4HOFN42wHMBuChkzMXAzIZbv0UhIjz7WYVyMTCzchmo+ejigd4YEZcNfxwbiIuBmZXbQM1Hk0YshQ1oX0cXtz22n89eequLgZmV1UDNR18YySDWt66u4Kzv3cGax/e5GJhZ2RVzn8I44DzgpcC47u0R8aEy5rLUw5t3sObx7bzzmHq+8sFTXAzMrKxqinjNT4AXAG8AbgPmADvKGcoOaGxuBWDJ7DoXBDMru2KKwtER8TlgZ0RcBbwFOKm8saxbY3Mrc6ePZ+b4Yv6pzMyGpphvmu4B77ZKOhaYAhxavkjWrasrWLG+jSXzZ2QdxcyqRDFF4XJJ04DPAdcDDwL/UtZUBsDap7azbfd+Tj7KRcHMRkYxQ2f/MF28DVhQ3jhWqKc/YcEMHr5nXcZpzKwaDHTz2nsj4qf93cTmm9fKr6mljSNnTOCwqeN5OOswZlYVBjpTmJj+7OsmtihDFivQ2RWsWN/KW142O+soZlZFBrp57fvp4u8j4o7C5ySdWtZUxoNPbGfHng73J5jZiCqmo/lbRW6zYdTUcqA/wcxspAzUp3AycApwSK9+hclAbbmDVbvGllYWzJzIrMnjBn+xmdkwGehMYQzQQFI4JhU8tgPvHMpBJV0k6QFJayT9QtI4SfMlrZC0TtIvJY0ZyjHyrKOzizvXt7HETUdmNsIG6lO4TdLtwMuHc3A8SYcDnwAWRsRuSVcD7wbeDHwtIpZJ+leS8Za+N1zHzZM1T2ynfW+Hm47MbMQN2KcQEZ3AYWU4bh0wXlIdMAF4EngtcE36/FXAmWU4bi4c6E+YnnESM6s2ihj46lJJ3wMOB34F7OzePpQ5miVdCPwzsBu4GbgQaIqIo9Pn5wI3RcSxfbz3fOB8gFmzZi1atmxZSRna29tpaGgo7Q9QZpeu3EPr7i7+z59N6NlWyXl7y1NWyFfePGWFfOXNU1YYWt6lS5euiojFfT4ZEQM+gB/18bhysPcNsL9pwH8BhwD1wG+B9wLrCl4zF1gz2L4WLVoUpVq+fHnJ7y2nfR2d8ZLP3RR//5v7nrO9UvP2JU9ZI/KVN09ZI/KVN09ZI4aWF1gZ/XyvFjPMxXDP1fw6YH1EPAMg6VrgVGCqpLqI6CAZnvvxYT5uLtz/+DZ27evk5AUzs45iZlUoi0l2NgJLJE0gaT46HVgJLCe5qmkZcC5wXYn7z7Xu8Y5Ocn+CmWVgxCfZiYgVJB3Kq4H70wyXA58GLpa0DpgBXFHqMfKsqaWVY2Y1MLNhbNZRzKwKDXqmQDLJzrsknRERV0n6OfD/hnLQiPg88Plem1uAE4ey37zb19HFyg1bOHvxnKyjmFmV8iQ7FeS+TVvZvb/T4x2ZWWaKOVPoPclOQ7psw6ynP8EzrZlZRjzJTgVpWt/Ki18wiWkTq3aEDzPL2KDNR5JmSPqWpNWSVkn6uiT/KjvM9nZ0snLDFjcdmVmmiulTWAZsBt5Bcsnos8AvyxmqGt2zcSt7O7o42eMdmVmGiulTmB0RXyxY/ydJf1GuQNWqqaUNyf0JZpatYs4Ubpb0bkk16eNs4HflDlZtGlueZeHsyUyZUJ91FDOrYsUUhQ8DPwf2po9lwEck7ZC0vZzhqsWe/Z2s3rjVTUdmlrlirj6aNBJBqtndG7eyr6PL8yeYWeaKOVOwMmtsaaVGcKLHOzKzjLkoVICm5laOPXwKk8e5P8HMsuWikLHd+zq557Gtbjoys4rQb5+CpAHbMiKibfjjVJ/VG7ewr9P3J5hZZRioo3kVEICAI4At6fJUkjkR5pc7XDVobG6ltkYsnjct6yhmZv03H0XE/IhYAPweeFtEzIyIGcBbSeZVtmHQ1JL0J0xyf4KZVYBi+hSWRMSN3SsRcRNwSvkiVY9d+zq4d5PvTzCzylHMMBdPSPos8NN0/T3AE+WLVD1WbtjC/s7wIHhmVjGKOVM4BzgE+A1wbbp8TjlDVYumllbqasTiI92fYGaVYcAzBUm1wLci4j0jlKeqNLa08vI5U5g4tpgTNjOz8hvwTCEiOoEjJXnWl2HWvreD+zZtc9ORmVWUYn5FbQHukHQ9sLN7Y0RcVrZUVWDlhjY6u8I3rZlZRSmmKDSnjxrAg+MNk8aWVuprxeIjPd6RmVWOYkZJ/QKApAkRsav8kapDU3Mrx82dyvgxtVlHMTPrUcwczSdLehB4KF1/haTvlj3ZKLZjz37uf3ybm47MrOIUc0nq14E3AK0AEXEv8OoyZhr17trQRlfgm9bMrOIUNUpqRDzWa1NnGbJUjcbmVsbU1nC8708wswpTTEfzY5JOAUJSPXAhsLa8sUa3ppY2jjtiKuPq3Z9gZpWlmDOFvwY+BhwOPA4cl65bCbbt3s8DT2xz05GZVaRizhTkO5qHz53r0/4E37RmZhWomDOFOyTdLOk8SVPLHWi0a2ppZWxdDcfNnZp1FDOz5xm0KETEMcBngZcCqyXdIOm9QzmopKmSrpH0kKS16WWv0yXdIumR9Oeo7IVtbG7l+COmuT/BzCpSsVcf3RkRFwMnAm3AVUM87jeA/4yIFwOvIOm4vgT4Q0S8EPhDuj6qbN21j7VPbXfTkZlVrGJuXpss6VxJNwH/DTxJUhxKImkKyX0OVwBExL6I2AqcwYFicxVwZqnHqFQr1rcR7k8wswqmiBj4BdJ64LfA1RHROOQDSscBlwMPkpwlrCK5zPXxiJiavkbAlu71Xu8/HzgfYNasWYuWLVtWUo729nYaGhpKem+pfrZ2L7c91sF3XjeB+hod1HuzyFuqPGWFfOXNU1bIV948ZYWh5V26dOmqiFjc55MRMeCDA4WjAWgY7PVF7G8x0AGclK5/A/gisLXX67YMtq9FixZFqZYvX17ye0v1hq/dFu/5QVNJ780ib6nylDUiX3nzlDUiX3nzlDViaHmBldHP92oxfQovlXQ38ADwoKRVko4tqTwlNgGbImJFun4NcDzwtKTZAOnPzUM4RsVp27mPh57a4aYjM6toxRSFy4GLI+LIiDgC+FS6rSQR8RTJXdIvSjedTtKUdD1wbrrtXOC6Uo9RiVa0tAKwZIGHyjazylXMzWsTI2J590pE3Cpp4hCPewHws3RGtxbggyQF6mpJ5wGPAmcP8RgVpbGllQljann5nKlZRzEz61dRM69J+hzwk3T9vSRf5CWLiHtI+hZ6O30o+61kjc2tLJ43nfraoq4CNjPLRDHfUB8CDgGuBX4NzEy3WZGebd/LI5vb3XRkZhWvmJnXtgCfGIEso1ZT2p/gQfDMrNIVc/PaLYVjHkmaJul3ZU01yjQ2tzJxTC0vO3xK1lHMzAZUTPPRzEjuOAZ6zhwOLVuiUaippZUT5k+nzv0JZlbhivmW6pJ0RPeKpCOBgW+Dth6bt++h+Zmdbjoys1wo5uqjvwdul3QbIODPSIeZsME1dvcn+KY1M8uBYjqa/1PS8cCSdNMnI+LZ8sYaPZpa2pg0to6FsydnHcXMbFDFnCmQFoEbypxlVGpqaeVE9yeYWU74m6qMntq2h/XP7nTTkZnlhotCGTX1jHfkomBm+VDMfQpHSRqbLp8m6ROeq7k4jc2tTB5Xx0vcn2BmOVHMmcKvgU5JR5OMjjoX+HlZU40SjS2tnLRgBrUHOaGOmVlWirpPISI6gD8HvhURfwvMLm+s/Ht86242tu1y05GZ5UoxRWG/pHNI5jjovgKpvnyRRoemZo93ZGb5U0xR+CBwMvDPEbFe0nwODKNt/WhsaWXqhHpe/IJJWUcxMytaMTevPUjBKKkRsR74cjlDjQZNLa2cNH86Ne5PMLMcKebqo1PTkVIfltQiab2kIU2yM9o91raLTVt2u+nIzHKnmDuarwAuAlYBneWNMzocGO9oZsZJzMwOTjFFYVtE3FT2JKNIU0sr0yeO4ZhZDVlHMTM7KMUUheWSvkIyHefe7o0RsbpsqXIsImhqbmXJgulI7k8ws3wppiiclP5cXLAtgNcOf5z829i2iye27eGj7k8wsxwq5uqjpSMRZLRo8vwJZpZjxVx9NEXSZZJWpo9LJXmy4X40Nrcys2EsRx3i/gQzy59ibl67EtgBnJ0+tgM/KmeovIoIGlvcn2Bm+VVMn8JREfGOgvUvSLqnTHlybUPrLp7evtdNR2aWW8WcKeyW9KruFUmnArvLFym/Gps9f4KZ5VsxZwofBa5K+xEEtAEfKGeovGpsaeXQSWNZMHNi1lHMzEpSzNVH9wCvkDQ5Xd9e7lB5FBE0tbRyylEz3J9gZrnVb1GQ9N6I+Kmki3ttByAiLitztlxpfmYnz+zY66YjM8u1gc4UuttA+hr7OcqQJdd6xjtyUTCzHOu3KETE99PF30fEHYXPpZ3NVqCppZXZU8Zx5IwJWUcxMytZMVcffavIbQdFUq2kuyXdkK7Pl7RC0jpJv5Q0ZqjHGCkRwYqWVpYscH+CmeXbQH0KJwOnAIf06leYDNQOw7EvBNam+4Nk4p6vRcQySf8KnAd8bxiOU3aPbG7n2fZ9bjoys9wb6ExhDNBAUjgmFTy2A+8cykElzQHeAvwwXRfJAHvXpC+5CjhzKMcYSR7vyMxGC0UM3Gcs6ciIeDRdrgEahnpZqqRrgP9LUmT+huS+h6aIODp9fi5wU0Qc28d7zwfOB5g1a9aiZcuWlZShvb2dhobhGZ/o23fvYf22Lr76mvFlaz4azrzllqeskK+8ecoK+cqbp6wwtLxLly5dFRGL+3wyIgZ8AD8naeKZCDwIbAL+drD3DbC/twLfTZdPA24AZgLrCl4zF1gz2L4WLVoUpVq+fHnJ7y3U2dkVx33hd3HxL+8Zlv31Z7jyjoQ8ZY3IV948ZY3IV948ZY0YWl5gZfTzvVpMR/PCSM4MzgRuAuYD7yupPCVOBd4uaQOwjKTZ6BvAVEndfRxzgMeHcIwR8/DmHWzZtd9NR2Y2KhRTFOol1ZMUhesjYj9DuE8hIv4uIuZExDzg3cB/RcR7gOUc6Ks4F7iu1GOMpAPjHU3POImZ2dAVUxS+D2wgaT76o6QjSTqbh9ungYslrQNmAFeU4RjDrrG5lbnTxzNnmu9PMLP8K2bso28C3yzY9KikYZmNLSJuBW5Nl1uAE4djvyOlqytYsb6NN7x0VtZRzMyGRTEzr82SdIWkm9L1hSTNO1Vv7VPb2bZ7v8c7MrNRo5jmox8DvwMOS9cfBj5Zpjy50t2f4E5mMxstiikKMyPiaqALICI6gM6ypsqJppZW5s2YwOwp47OOYmY2LIopCjslzSC94kjSEmBbWVPlQGfan+CmIzMbTYqZee1i4HrgKEl3AIcwxGEuRoMHn9jOjj0dbjoys1GlmKuPVkt6DfAikuk4/5Teq1DVGlueBTwfs5mNLoMWBUnv77XpeElExL+VKVMuNLW0sWDmRGZNHpd1FDOzYVNM89EJBcvjgNOB1UDVFoWOzi7uXN/G2487bPAXm5nlSDHNRxcUrkuaSjJmUdVa88R22vd2eP4EMxt1irn6qLedJIPiVa3u+RPcn2Bmo00xfQr/zoEB8GqAhcDV5QxV6RqbWzn60AYOmTQ26yhmZsOqmD6FrxYsdwCPRsSmMuWpePs7u7hrQxvvOH5O1lHMzIZdMc1HTwBT0kdVFwSA+x/fxq59nb4/wcxGpX6LgqSpkn5LMu7RB9LHbZK+r8QbRyRhheke7+ik+Z4/wcxGn4Gaj74F3AOcFRFdAEomIP4s8O/AMemjqjS1tPKiWZOY0eD+BDMbfQYqCksi4jnTbqZze35R0maSaTWryr6OLlZu2MJfnDA36yhmZmVRyiWpANsj4pFhTZID923ayu79nZ5608xGrYGKwn9L+oe0yaiHpM8C/13eWJWpsbkVCU6a705mMxudBmo+uoBknuR1ku5Jtx0H3A18qLyxKlPT+lZe/ILJTJs4JusoZmZl0W9RiIjtwLskHUVywxrAgxHRPCLJKszejk5WbtjCX550RNZRzMzKppixj5qBqiwEhe7ZuJW9HV0e78jMRrVSO5qrTlNLm/sTzGzUc1EoUmPLsyycPZkpE+qzjmJmVjYDFgVJtZIeGqkwlWrP/k5Wb9zqpiMzG/UGLAoR0Qn8SVJV967evXEr+zq6PN6RmY16xYySOg14QNKdJHMpABARby9bqgrT2NJKjeAEj3dkZqNcMUXhc2VPUeGamls59vApTB7n/gQzG90G7WiOiNuADUB9unwXyRzNVWH3vk7uecz9CWZWHQYtCpI+DFwDfD/ddDjw2zJmqiirN25hX2eXp940s6pQzCWpHyMZEXU7QDoQ3qHlDFVJGptbqa2R+xPMrCoUUxT2RsS+7hVJdRyYs/mgSZorabmkByU9IOnCdPt0SbdIeiT9Oa3UYwynppZWXnb4FBrGFtP9YmaWb8UUhdskfQYYL+n1wK9IJtkpVQfwqYhYCCwBPiZpIXAJ8IeIeCHwh3Q9U7v2dXDvpq1uOjKzqlFMUbgEeAa4H/gIcCPJ7GsliYgnI2J1urwDWEvST3EGcFX6squAM0s9xnBZuWEL+zvD9yeYWdVQMpnaIC+SxgAvJmk2+lNhc9KQDi7NA/4IHAtsjIip6XYBW7rXe73nfOB8gFmzZi1atmxZScdub2+noaFhwNdc8/A+blq/n++cPoFxdRrwteVWTN5KkaeskK+8ecoK+cqbp6wwtLxLly5dFRGL+3wyIgZ8AG8BHgNuBW4DNgJvGux9Rey3AVhFMgc0wNZez28ZbB+LFi2KUi1fvnzQ15z5ndvjz79ze8nHGE7F5K0Uecoaka+8ecoaka+8ecoaMbS8wMro53u1mOajS4GlEXFaRLwGWAp8raTylJJUD/wa+FlEXJtuflrS7PT52cDmoRxjqNr3dnDfpm1uOjKzqlJMUdgREesK1luAHaUeMG0augJYGxGXFTx1PXBuunwucF2pxxgOKze00dkVnLxgZpYxzMxGVL/XWUo6K11cKelG4GqSPoV3kdzVXKpTgfcB9xdM8/kZ4EvA1ZLOAx4Fzh7CMYassaWV+lqx6MiKuDLWzGxEDHTx/dsKlp8GXpMuPwOML/WAEXE70F+v7eml7ne4NTW3ctzcqYwfU5t1FDOzETPQHM0fHMkglWTHnv3c//g2Pr706KyjmJmNqEFv05U0H7gAmFf4+hjFQ2fftaGNroAl7mQ2sypTzNgNvyXpGP53oKusaSpEY3MrY2prOP4I9yeYWXUppijsiYhvlj1JBWlqaeOVR0xlXL37E8ysuhRzSeo3JH1e0smSju9+lD1ZRrbt3s8DT/j+BDOrTsWcKbyM5BLS13Kg+SjS9VHnzvVpf4IHwTOzKlRMUXgXsCCGabyjStfU0srYuhpeecTUrKOYmY24YpqP1gBTy5yjYjQ2t7LoyGmMrXN/gplVn2LOFKYCD0m6C9jbvXE0XpK6ddc+1j61nYted0zWUczMMlFMUfh82VNUiKaWNiJwJ7OZVa1Bi0JE3DYSQSpBU0sr4+preMWcqVlHMTPLRDF3NO/gwJzMY4B6YGdETC5nsCw0tbSy+MjpjKkrpqvFzGz0GfTbLyImRcTktAiMB94BfLfsyUZYa/teHnpqh5uOzKyqHdSvxOmkPb8F3lCeONm5c30b4PsTzKy6FdN8dFbBag2wGNhTtkQZaWxpZcKYWl4+Z0rWUczMMlPM1UeF8yp0ABuAM8qSJkONza0snjed+lr3J5hZ9Srm6qNRP6/Cs+17eWRzO2cdPyfrKGZmmRpoOs5/GOB9ERFfLEOeTDS1tAKwZMH0jJOYmWVroDOFnX1smwicB8wARk1RaGxupWFsHS873P0JZlbdBpqO89LuZUmTgAuBDwLLgEv7e18eNbW0csK8adS5P8HMqtyA34KSpkv6J+A+kgJyfER8OiI2j0i6EbB5+x6an9npS1HNzBi4T+ErwFnA5cDLIqJ9xFKNoMa0P8E3rZmZDXym8CngMOCzwBOStqePHZK2j0y88mtqaWPS2Dpeepj7E8zMBupTqIoG9qaWVk6cP53aGmUdxcwsc1Xxxd+fp7btYf2zO910ZGaWquqicOD+BBcFMzOo8qLQ2NzKlPH1LJw96kYBNzMrSXUXhbQ/ocb9CWZmQBUXhdbdXWxs28XJbjoyM+tRtUXhobZOwPcnmJkVqtqisLati2kT6nnRrElZRzEzqxgVVRQkvVHSnyStk3RJOY/1UFsnJ82f4f4EM7MCFVMUJNUC3wHeBCwEzpG0sBzHeqxtF8/uDjcdmZn1UjFFATgRWBcRLRGxj2Q01rLM8Nbo+xPMzPqkiMg6AwCS3gm8MSL+Kl1/H3BSRHy81+vOB84HmDVr1qJly5Yd9LFWP93BrY/u4aITJiLlo/movb2dhoaGrGMUJU9ZIV9585QV8pU3T1lhaHmXLl26KiIW9/lkRFTEA3gn8MOC9fcB3x7oPYsWLYpSLV++vOT3ZiFPefOUNSJfefOUNSJfefOUNWJoeYGV0c/3aiU1Hz0OzC1Yn5NuMzOzEVJJReEu4IWS5ksaA7wbuD7jTGZmVWWgOZpHVER0SPo48DugFrgyIh7IOJaZWVWpmKIAEBE3AjdmncPMrFpVUvORmZllzEXBzMx6uCiYmVkPFwUzM+tRMXc0l0LSM8CjJb59JvDsMMYptzzlzVNWyFfePGWFfOXNU1YYWt4jI+KQvp7IdVEYCkkro7/bvCtQnvLmKSvkK2+eskK+8uYpK5Qvr5uPzMysh4uCmZn1qOaicHnWAQ5SnvLmKSvkK2+eskK+8uYpK5Qpb9X2KZiZ2fNV85mCmZn14qJgZmY9qqIoSLpS0mZJawq2fUXSQ5Luk/QbSVMzjNhD0lxJyyU9KOkBSRf2ev5TkkLSzKwyFpI0TtKdku5N834h3S5J/yzpYUlrJX0i66zdJNVKulvSDen66ZJWS7pH0u2Sjs46YzdJUyVdk/5fXSvpZEnTJd0i6ZH057QKyPmi9O+v+7Fd0icr9XMGIOmi9P/sGkm/kDSu4LlvSmrPMl8hSRemOR+Q9MmC7Rekf78PSPqXYTlYf7PvjKYH8GrgeGBNwbb/AdSly18Gvpx1zjTLbOD4dHkS8DCwMF2fSzK0+KPAzKyzppkENKTL9cAKYAnwQeDfgJr0uUOzzlqQ+WLg58AN6frDwEvS5f8J/DjrjAVZrwL+Kl0eA0wF/gW4JN12SaX83y3IXAs8BRxZwZ+zw4H1wPh0/WrgA+nyYuAnQHvWOdM8xwJrgAkkI1v/HjgaWJouj01fNyyfsao4U4iIPwJtvbbdHBEd6WoTyUxvmYuIJyNidbq8A1hL8h8Y4GvA/wIq5uqASHT/RlWfPgL4KPCPEdGVvm5zRhGfQ9Ic4C3ADws2BzA5XZ4CPDHSufoiaQrJLzRXAETEvojYCpxBUixIf56ZRb4BnA40R8Sjlfo5S9UB4yXVkXzhPiGpFvgKyeesUrwEWBERu9K/y9uAs0g+Y1+KiL0wfJ+xqigKRfgQcFPWIXqTNA94JbBC0hnA4xFxb7apni9tjrkH2AzcEhErgKOAv5C0UtJNkl6YacgDvk7yge8q2PZXwI2SNpHMDf6lDHL1ZT7wDPCjtLnrh5ImArMi4sn0NU8BszJL2Ld3A7/oY3vFfM4i4nHgq8BG4ElgW0TcDHwcuL7g77cSrAH+TNIMSROAN5O0GhyTbl8h6TZJJwzHwaq+KEj6e6AD+FnWWQpJagB+DXySJN9ngH/IMlN/IqIzIo4j+S3wREnHAmOBPZHchv8D4MoMIwIg6a3A5ohY1eupi4A3R8Qc4EfAZSMerm91JM2e34uIVwI7SZqLekTSblAxZ47pVLpvB37Va3tFfc7SfpgzSArvYcBESe8H3gV8K8tsvUXEWpKmt5uB/wTuATpJ/n9MJ2mu/Vvgakka6vGquihI+gDwVuA96YerIkiqJykIP4uIa0l+654P3CtpA8mX72pJL8gu5fOlTRvLgTcCm4Br06d+A7w8o1iFTgXenv4dLgNeK+k/gFekZzcAvwROyShfb5uATQXZriEpEk9Lmg2Q/qyIprnUm4DVEfF094YK/Zy9DlgfEc9ExH6S/6tfIGmrX5f+H5kgaV2GGXtExBURsSgiXg1sIekH2wRcmzbh3kly9jvkC1CqtihIeiNJM8LbI2JX1nm6pZX+CmBtRFwGEBH3R8ShETEvIuaR/Gc4PiKeyjAqAJIO6b6iRNJ44PXAQ8BvSTrCAF5D8p84UxHxdxExJ/07fDfwXyS/LU6RdEz6steT9ONkLv33fUzSi9JNpwMPAtcD56bbzgWuyyBef86hoOmoUj9nJM1GSyRNSD9zpwOXRcQLCj5nuyKiIq5Ek3Ro+vMIkv6En1PwGUv//45hGEZ5rag5mstF0i+A04CZabvx54G/I2niuCU942qKiL/OLOQBp5K0a9+fttMDfCaS+asr0WzgqrSDrga4OiJukHQ78DNJFwHtJO32FSciOiR9GPi1pC6S38I+lHGsQheQ/D2OAVpIruqqIWkqOI/kSrSzM8zXI+3veD3wkYLN36YCP2cRsULSNcBqkmatu6nsYS5+LWkGsB/4WERslXQlcKWSS+33AecOx5mYh7kwM7MeVdt8ZGZmz+eiYGZmPVwUzMysh4uCmZn1cFEwM7MeLgqWe0pGjb20YP1vJP3vYdr3jyW9czj2Nchx3pWOgrq81/Z5kv6y3Mc36+aiYKPBXuAsVchw4t3SgdaKdR7w4YhY2mv7PMBFwUaMi4KNBh0kNx5d1PuJ3r/pd4+RL+m0dBCx6yS1SPqSpPcomRvifklHFezmdenAfg+n4yd1DwL4FUl3pXMFfKRgv/9P0vUkdx/3znNOuv81kr6cbvsH4FXAFZK+0ustXyIZ9OweJeP/z0v3vzp9nJLuo0bSd5WMrX+LpBu7/9zpn+3BNOdXS/1LtupQFXc0W1X4DnCfDm6ikVeQDEvcRnK38A8j4kQlExtdQDIYISS/rZ9IMgbVciWT8LyfZGTNEySNBe6QdHP6+uOBYyNifeHBJB1GMrDZIpI7p2+WdGZE/KOk1wJ/ExEre2W8JN3eXYwmAK+PiD1KRp79Bcn4/2elORcCh5IM1XFlehfsnwMvjohQBU1yY5XJZwo2KkTEdpJJfQ5mhre70vkr9gLNJKNQAtxP8gXb7eqI6IqIR0iKx4tJJo95fzoUyQpgBtA9PPidvQtC6gTg1nQQtu4RQ199EHkhma/iB5LuJxmJdGG6/VXAr9KcT5EMTAiwDdhDchZyFlBJ4w9ZBXJRsNHk6yRt8xMLtnWQ/j+XVEMyaFi3vQXLXQXrXTz3LLr3WDBBMuPcBRFxXPqYn47HD8kQ1+VyEfA0yVnOYp7753metPicSDLC6ltJhl4265eLgo0aEdFGMq3ieQWbN5A010Ayzn99Cbt+V9pmfxSwAPgTybSoH02HOUfSMemAcAO5E3iNpJnpAILnkMyiNZAdJNOydpsCPJnOaPc+kqkvAe4A3pHmnEUyAGT3vBxT0gEVLyIpJmb9cp+CjTaXksye1e0HwHWS7iX5LbmU3+I3knyhTwb+Om3P/yFJE9PqdOjlZxhkWsyIeFLSJSRNOwL+IyIGG/b6PqAzzf9j4LskI2a+v9ef59ccGFr7MZLRP7eRFJTrlExKL5L5qc365VFSzUYJSQ0R0Z52Lt8JnFoJc25YvvhMwWz0uCG9umgM8EUXBCuFzxTMzKyHO5rNzKyHi4KZmfVwUTAzsx4uCmZm1sNFwczMevx/5gQuK7TcjNMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with  48 tags we are covering  100.0 % of questions\n"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(questions_explained)\n",
    "xlabel = list(0+np.array(range(0,92,3))*4)\n",
    "ax.set_xticklabels(xlabel)\n",
    "plt.xlabel(\"Number of tags\")\n",
    "plt.ylabel(\"Number Questions coverd partially\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "print(\"with \",48,\"tags we are covering \",questions_explained[7],\"% of questions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "id": "ccdcfe76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of questions that are not covered : 13 out of  2219\n"
     ]
    }
   ],
   "source": [
    "multilabel_yx = tags_to_choose(48)\n",
    "print(\"number of questions that are not covered :\", questions_explained_fn(48),\"out of \", total_qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "id": "44ad2238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tags in sample : 92\n",
      "number of tags taken : 48 ( 52.17391304347826 %)\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of tags in sample :\", multilabel_y.shape[1])\n",
    "print(\"number of tags taken :\", multilabel_yx.shape[1],\"(\",(multilabel_yx.shape[1]/multilabel_y.shape[1])*100,\"%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "id": "f9e4dceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into train and test \n",
    "total_size=df.shape[0]\n",
    "#performing a 90:10 split\n",
    "train_size=int(0.90*total_size)\n",
    "\n",
    "x_train=df.head(train_size)\n",
    "x_test=df.tail(total_size - train_size)\n",
    "\n",
    "y_train = multilabel_yx[0:train_size,:]\n",
    "y_test = multilabel_yx[train_size:total_size,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5b5abf",
   "metadata": {},
   "source": [
    "# Featurizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602ebcaf",
   "metadata": {},
   "source": [
    "<h3> one hot encoding </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "id": "f0e77795",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding the categorical feature- difficulty\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(x_train['difficulty'].values) # fit has to happen only on train data\n",
    "\n",
    "# we use the fitted CountVectorizer to convert the text to vector\n",
    "x_train_difficulty = vectorizer.transform(x_train['difficulty'].values)\n",
    "x_test_difficulty = vectorizer.transform(x_test['difficulty'].values)\n",
    "\n",
    "#one hot encoding the categorical feature- difficulty\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(x_train['topic'].values) # fit has to happen only on train data\n",
    "\n",
    "# we use the fitted CountVectorizer to convert the text to vector\n",
    "x_train_topic = vectorizer.transform(x_train['topic'].values)\n",
    "x_test_topic = vectorizer.transform(x_test['topic'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38ef130",
   "metadata": {},
   "source": [
    "<h3> MinMax Scaler </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "id": "bda5e05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardising the numerical values using MinMax scaler\n",
    "\n",
    "#standardising likes\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_train['likes'].values.reshape(-1, 1))\n",
    "x_train_likes = scaler.transform(x_train['likes'].values.reshape(-1, 1))\n",
    "x_test_likes = scaler.transform(x_test['likes'].values.reshape(-1, 1))\n",
    "\n",
    "#standardising dislikes\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_train['dislikes'].values.reshape(-1, 1))\n",
    "x_train_dislikes = scaler.transform(x_train['dislikes'].values.reshape(-1, 1))\n",
    "x_test_dislikes = scaler.transform(x_test['dislikes'].values.reshape(-1, 1))\n",
    "\n",
    "#standardising totalAccepted\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_train['totalAccepted'].values.reshape(-1, 1))\n",
    "x_train_accepted = scaler.transform(x_train['totalAccepted'].values.reshape(-1, 1))\n",
    "x_test_accepted = scaler.transform(x_test['totalAccepted'].values.reshape(-1, 1))\n",
    "\n",
    "#standardising totalSubmission\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_train['totalSubmission'].values.reshape(-1, 1))\n",
    "x_train_submission = scaler.transform(x_train['totalSubmission'].values.reshape(-1, 1))\n",
    "x_test_submission = scaler.transform(x_test['totalSubmission'].values.reshape(-1, 1))\n",
    "\n",
    "#standardising acRate\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_train['acRate'].values.reshape(-1, 1))\n",
    "x_train_acRate = scaler.transform(x_train['acRate'].values.reshape(-1, 1))\n",
    "x_test_acRate = scaler.transform(x_test['acRate'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "id": "3946b60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop similar questions column\n",
    "x_train.drop('similar_questions', axis=1, inplace=True)\n",
    "x_test.drop('similar_questions', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c41dee",
   "metadata": {},
   "source": [
    "<h3> TF-IDF Vectorization</h3>\n",
    "- creating text vectorizations for each column seperately and then concatenating the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "id": "7594e180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to run this cell : 0:00:00.051194\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "vectorizer = TfidfVectorizer(min_df=0.0009, max_features=300, smooth_idf=True, norm=\"l2\", \\\n",
    "                             tokenizer = lambda x: x.split(), sublinear_tf=False, ngram_range=(1,3))\n",
    "\n",
    "x_train_tfidf_title = vectorizer.fit_transform(x_train['title'])\n",
    "x_test_tfidf_title = vectorizer.transform(x_test['title'])\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "id": "c1947f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to run this cell : 0:00:00.340958\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "vectorizer = TfidfVectorizer(min_df=0.0009, max_features=400, smooth_idf=True, norm=\"l2\", \\\n",
    "                             tokenizer = lambda x: x.split(), sublinear_tf=False, ngram_range=(1,3))\n",
    "\n",
    "x_train_tfidf_content = vectorizer.fit_transform(x_train['content'])\n",
    "x_test_tfidf_content = vectorizer.transform(x_test['content'] )\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "id": "029bea95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to run this cell : 0:00:00.152002\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "vectorizer = TfidfVectorizer(min_df=0.0009, max_features=350, smooth_idf=True, norm=\"l2\", \\\n",
    "                             tokenizer = lambda x: x.split(), sublinear_tf=False, ngram_range=(1,3))\n",
    "\n",
    "x_train_tfidf_hints = vectorizer.fit_transform(x_train['hints'])\n",
    "x_test_tfidf_hints = vectorizer.transform(x_test['hints'])\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "id": "cdfda89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #stacking all the featurizations created above into a single array\n",
    "# X_tr = hstack((x_train_tfidf, x_train_likes, x_train_dislikes, x_train_accepted, x_train_submission,\n",
    "#                x_train_acRate, x_train_topic, x_train_difficulty)).tocsr()\n",
    "\n",
    "# X_te = hstack((x_test_tfidf, x_test_likes, x_test_dislikes, x_test_accepted, x_test_submission,\n",
    "#                x_test_acRate, x_test_topic, x_test_difficulty)).tocsr()\n",
    "# print(X_tr.shape, y_train.shape)\n",
    "# print(X_te.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "id": "f0fe99e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1997, 1062) (1997, 48)\n",
      "(222, 1062) (222, 48)\n"
     ]
    }
   ],
   "source": [
    "#stacking all the featurizations created above into a single array\n",
    "X_tr = hstack((x_train_tfidf_title, x_train_tfidf_content, x_train_tfidf_hints, x_train_likes, x_train_dislikes, x_train_accepted, x_train_submission,\n",
    "               x_train_acRate, x_train_topic, x_train_difficulty)).tocsr()\n",
    "\n",
    "X_te = hstack((x_test_tfidf_title, x_test_tfidf_content, x_test_tfidf_hints, x_test_likes, x_test_dislikes, x_test_accepted, x_test_submission,\n",
    "               x_test_acRate, x_test_topic, x_test_difficulty)).tocsr()\n",
    "print(X_tr.shape, y_train.shape)\n",
    "print(X_te.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2118eb",
   "metadata": {},
   "source": [
    "<h3>Applying Logistic Regression with OneVsRest Classifier </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "id": "bf73ab64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.22072072072072071\n",
      "macro f1 score : 0.39429792296183913\n",
      "micro f1 score : 0.5879765395894428\n",
      "hamming loss : 0.05274024024024024\n",
      "Precision recall report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85       115\n",
      "           1       1.00      0.84      0.91        44\n",
      "           2       0.76      0.70      0.73        37\n",
      "           3       0.62      0.38      0.47        34\n",
      "           4       0.56      0.56      0.56        34\n",
      "           5       0.65      0.45      0.53        38\n",
      "           6       0.56      0.39      0.46        38\n",
      "           7       0.58      0.58      0.58        36\n",
      "           8       0.60      0.56      0.58        27\n",
      "           9       0.70      0.78      0.74        18\n",
      "          10       0.50      0.28      0.36        29\n",
      "          11       0.55      0.19      0.29        31\n",
      "          12       1.00      0.89      0.94        19\n",
      "          13       1.00      1.00      1.00        19\n",
      "          14       0.38      0.36      0.37        14\n",
      "          15       0.80      0.67      0.73        12\n",
      "          16       0.00      0.00      0.00        17\n",
      "          17       0.00      0.00      0.00        17\n",
      "          18       1.00      0.36      0.53        14\n",
      "          19       1.00      0.36      0.53        14\n",
      "          20       0.40      0.31      0.35        13\n",
      "          21       0.88      1.00      0.93         7\n",
      "          22       1.00      0.14      0.25        14\n",
      "          23       1.00      0.14      0.25        14\n",
      "          24       1.00      0.14      0.25        14\n",
      "          25       0.40      0.50      0.44         4\n",
      "          26       0.00      0.00      0.00         7\n",
      "          27       0.00      0.00      0.00         6\n",
      "          28       1.00      0.25      0.40         8\n",
      "          29       0.67      0.31      0.42        13\n",
      "          30       0.33      0.08      0.12        13\n",
      "          31       0.67      0.50      0.57         8\n",
      "          32       0.60      0.38      0.46         8\n",
      "          33       1.00      0.75      0.86        12\n",
      "          34       1.00      0.75      0.86        12\n",
      "          35       0.33      0.20      0.25         5\n",
      "          36       0.33      0.20      0.25         5\n",
      "          37       0.00      0.00      0.00         7\n",
      "          38       0.00      0.00      0.00         4\n",
      "          39       1.00      0.14      0.25         7\n",
      "          40       0.00      0.00      0.00         1\n",
      "          41       0.00      0.00      0.00         1\n",
      "          42       0.00      0.00      0.00         2\n",
      "          43       0.00      0.00      0.00         2\n",
      "          44       0.00      0.00      0.00         4\n",
      "          45       0.00      0.00      0.00         4\n",
      "          46       1.00      0.75      0.86         4\n",
      "          47       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.72      0.50      0.59       810\n",
      "   macro avg       0.54      0.35      0.39       810\n",
      "weighted avg       0.67      0.50      0.55       810\n",
      " samples avg       0.73      0.56      0.60       810\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier = OneVsRestClassifier(SGDClassifier(loss='log', alpha=0.0002, penalty='l1'), n_jobs=-1)\n",
    "classifier.fit(X_tr, y_train)\n",
    "predictions = classifier.predict(X_te)\n",
    "\n",
    "print(\"accuracy :\",metrics.accuracy_score(y_test,predictions))\n",
    "print(\"macro f1 score :\",metrics.f1_score(y_test, predictions, average = 'macro'))\n",
    "print(\"micro f1 score :\",metrics.f1_score(y_test, predictions, average = 'micro'))\n",
    "print(\"hamming loss :\",metrics.hamming_loss(y_test,predictions))\n",
    "print(\"Precision recall report :\\n\",metrics.classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "id": "1d91acad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1997, 500)"
      ]
     },
     "execution_count": 633,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for finding similar question I will create a tfidf vectorizer on titles only\n",
    "vectorizer = TfidfVectorizer(min_df=0.0009, max_features=500, ngram_range=(1,3))\n",
    "X = vectorizer.fit_transform(x_train['title'])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "id": "cd1e1a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deton maximum bomb\n"
     ]
    }
   ],
   "source": [
    "#take a query from test data \n",
    "print(x_test['title'].iloc[6])\n",
    "transformed_title = vectorizer.transform([x_test['title'].iloc[6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "id": "982bc384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question ID: 164, similar_question: maximum gap, Similarity score:1.0\n",
      "question ID: 1829, similar_question: maximum unit truck, Similarity score:1.0\n"
     ]
    }
   ],
   "source": [
    "#finding similarity of the test query with all the sentences in the train data\n",
    "#compute cosine similarity between tfidf vector representations\n",
    "results = cosine_similarity(X, transformed_title).reshape((-1,))\n",
    "\n",
    "#get top 2 most similar questions\n",
    "for i in results.argsort()[-2:][::-1]:\n",
    "    print('question ID: {}, similar_question: {}, Similarity score:{}'.format(x_train.iloc[i,0], x_train.iloc[i,1],results[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66f29dc",
   "metadata": {},
   "source": [
    "<h3> 4.5.3 Applying SVM with OneVsRest Classifier </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "id": "16fcd903",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.18018018018018017\n",
      "macro f1 score : 0.44210120269237035\n",
      "micro f1 scoore : 0.5527136618839675\n",
      "hamming loss : 0.06728603603603604\n",
      "Precision recall report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.84       115\n",
      "           1       0.88      0.86      0.87        44\n",
      "           2       0.50      0.68      0.57        37\n",
      "           3       0.46      0.47      0.46        34\n",
      "           4       0.46      0.50      0.48        34\n",
      "           5       0.50      0.47      0.49        38\n",
      "           6       0.49      0.45      0.47        38\n",
      "           7       0.52      0.61      0.56        36\n",
      "           8       0.52      0.63      0.57        27\n",
      "           9       0.50      0.78      0.61        18\n",
      "          10       0.42      0.34      0.38        29\n",
      "          11       0.39      0.29      0.33        31\n",
      "          12       0.89      0.84      0.86        19\n",
      "          13       1.00      1.00      1.00        19\n",
      "          14       0.47      0.57      0.52        14\n",
      "          15       0.53      0.67      0.59        12\n",
      "          16       0.14      0.12      0.13        17\n",
      "          17       0.14      0.18      0.16        17\n",
      "          18       0.35      0.43      0.39        14\n",
      "          19       0.35      0.43      0.39        14\n",
      "          20       0.45      0.38      0.42        13\n",
      "          21       0.78      1.00      0.88         7\n",
      "          22       0.57      0.29      0.38        14\n",
      "          23       0.43      0.21      0.29        14\n",
      "          24       0.57      0.29      0.38        14\n",
      "          25       0.40      0.50      0.44         4\n",
      "          26       0.14      0.14      0.14         7\n",
      "          27       0.00      0.00      0.00         6\n",
      "          28       0.50      0.25      0.33         8\n",
      "          29       0.25      0.15      0.19        13\n",
      "          30       0.29      0.15      0.20        13\n",
      "          31       0.71      0.62      0.67         8\n",
      "          32       0.42      0.62      0.50         8\n",
      "          33       1.00      0.83      0.91        12\n",
      "          34       1.00      0.92      0.96        12\n",
      "          35       0.40      0.40      0.40         5\n",
      "          36       0.33      0.40      0.36         5\n",
      "          37       0.00      0.00      0.00         7\n",
      "          38       0.50      0.25      0.33         4\n",
      "          39       1.00      0.14      0.25         7\n",
      "          40       0.50      1.00      0.67         1\n",
      "          41       0.50      1.00      0.67         1\n",
      "          42       0.33      0.50      0.40         2\n",
      "          43       0.00      0.00      0.00         2\n",
      "          44       0.20      0.25      0.22         4\n",
      "          45       0.00      0.00      0.00         4\n",
      "          46       0.67      0.50      0.57         4\n",
      "          47       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.56      0.55      0.55       810\n",
      "   macro avg       0.46      0.46      0.44       810\n",
      "weighted avg       0.55      0.55      0.54       810\n",
      " samples avg       0.60      0.61      0.57       810\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier = OneVsRestClassifier(SGDClassifier(loss='hinge', alpha=0.0001, penalty='l1'), n_jobs=-1)\n",
    "classifier.fit(X_tr, y_train)\n",
    "predictions = classifier.predict(X_te)\n",
    "\n",
    "print(\"accuracy :\",metrics.accuracy_score(y_test,predictions))\n",
    "print(\"macro f1 score :\",metrics.f1_score(y_test, predictions, average = 'macro'))\n",
    "print(\"micro f1 scoore :\",metrics.f1_score(y_test, predictions, average = 'micro'))\n",
    "print(\"hamming loss :\",metrics.hamming_loss(y_test,predictions))\n",
    "print(\"Precision recall report :\\n\",metrics.classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "id": "dd5c9947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-multilearn in c:\\users\\siddh\\anaconda3\\lib\\site-packages (0.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\siddh\\Anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-multilearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "id": "ec761aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.22972972972972974\n",
      "macro f1 score : 0.29438231026740175\n",
      "micro f1 score : 0.549618320610687\n",
      "hamming loss : 0.04983108108108108\n",
      "Precision recall report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.92       115\n",
      "           1       1.00      0.86      0.93        44\n",
      "           2       0.96      0.59      0.73        37\n",
      "           3       0.75      0.09      0.16        34\n",
      "           4       0.75      0.09      0.16        34\n",
      "           5       0.75      0.32      0.44        38\n",
      "           6       0.75      0.32      0.44        38\n",
      "           7       0.60      0.25      0.35        36\n",
      "           8       0.94      0.59      0.73        27\n",
      "           9       0.89      0.89      0.89        18\n",
      "          10       0.67      0.07      0.12        29\n",
      "          11       0.50      0.03      0.06        31\n",
      "          12       1.00      0.84      0.91        19\n",
      "          13       1.00      1.00      1.00        19\n",
      "          14       0.60      0.21      0.32        14\n",
      "          15       0.91      0.83      0.87        12\n",
      "          16       0.00      0.00      0.00        17\n",
      "          17       0.00      0.00      0.00        17\n",
      "          18       1.00      0.29      0.44        14\n",
      "          19       1.00      0.29      0.44        14\n",
      "          20       0.00      0.00      0.00        13\n",
      "          21       1.00      1.00      1.00         7\n",
      "          22       0.00      0.00      0.00        14\n",
      "          23       0.00      0.00      0.00        14\n",
      "          24       0.00      0.00      0.00        14\n",
      "          25       1.00      0.25      0.40         4\n",
      "          26       0.00      0.00      0.00         7\n",
      "          27       0.00      0.00      0.00         6\n",
      "          28       0.00      0.00      0.00         8\n",
      "          29       0.00      0.00      0.00        13\n",
      "          30       0.00      0.00      0.00        13\n",
      "          31       0.00      0.00      0.00         8\n",
      "          32       0.00      0.00      0.00         8\n",
      "          33       1.00      0.58      0.74        12\n",
      "          34       1.00      0.58      0.74        12\n",
      "          35       1.00      0.20      0.33         5\n",
      "          36       1.00      0.20      0.33         5\n",
      "          37       0.00      0.00      0.00         7\n",
      "          38       0.00      0.00      0.00         4\n",
      "          39       0.00      0.00      0.00         7\n",
      "          40       0.00      0.00      0.00         1\n",
      "          41       0.00      0.00      0.00         1\n",
      "          42       0.00      0.00      0.00         2\n",
      "          43       0.00      0.00      0.00         2\n",
      "          44       0.00      0.00      0.00         4\n",
      "          45       0.00      0.00      0.00         4\n",
      "          46       1.00      0.50      0.67         4\n",
      "          47       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.88      0.40      0.55       810\n",
      "   macro avg       0.46      0.25      0.29       810\n",
      "weighted avg       0.64      0.40      0.45       810\n",
      " samples avg       0.84      0.49      0.56       810\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "\n",
    "base_rf = RandomForestClassifier(n_estimators=50)\n",
    "chain = ClassifierChain(base_rf, order='random')\n",
    "y_tr = y_train.todense()\n",
    "chain.fit(X_tr, np.array(y_tr))\n",
    "predictions = chain.predict(X_te)\n",
    "print(\"accuracy :\",metrics.accuracy_score(y_test,predictions))\n",
    "print(\"macro f1 score :\",metrics.f1_score(y_test, predictions, average = 'macro'))\n",
    "print(\"micro f1 score :\",metrics.f1_score(y_test, predictions, average = 'micro'))\n",
    "print(\"hamming loss :\",metrics.hamming_loss(y_test,predictions))\n",
    "print(\"Precision recall report :\\n\",metrics.classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5171a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
